train_loss,valid_loss
4.609634459018707,4.60360801188151
4.6370112001895905,4.605086049397786
4.604338467121124,4.601526173909505
4.604550749063492,4.605178768157959
4.604288160800934,4.657417972564697
4.610383927822113,4.605105148315429
4.60524383187294,4.6051579780578615
4.6052069664001465,4.6051725540161135
4.605148881673813,4.604839822133382
4.6192706525325775,4.605158260345459
4.605151057243347,4.597821065266927
4.61669135093689,4.605206272125244
4.605276048183441,4.605170249938965
4.605178415775299,4.605192085266113
4.605211764574051,4.605164454142253
4.605201631784439,4.605170249938965
4.6052005887031555,4.605170249938965
4.605157256126404,4.605165003458659
4.6052020490169525,4.605170249938965
4.605176359415054,4.605170249938965
4.605169057846069,4.605170249938965
